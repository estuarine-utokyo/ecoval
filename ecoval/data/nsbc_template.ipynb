{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f533356",
   "metadata": {},
   "source": [
    "# Surface template_title validation using gridded observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a68d5a",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87e968",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "stamp = nc.session_info[\"stamp\"]\n",
    "out = \".trackers/\" + stamp + \".txt\"\n",
    "if not os.path.exists(\".trackers\"):\n",
    "    os.makedirs(\".trackers\")\n",
    "# save out as empty file\n",
    "with open(out, 'w') as f:\n",
    "    f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e31fe",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "grid = pd.read_csv(\"../../matched/model_grid.csv\")\n",
    "lon = grid.loc[:,[x for x in grid.columns if \"lon\" in x]].values\n",
    "lon = np.unique(lon)\n",
    "lon.sort()\n",
    "lat = grid.loc[:,[x for x in grid.columns if \"lat\" in x]].values\n",
    "lat = np.unique(lat)\n",
    "lat.sort()\n",
    "# get unique values in grid and sort them\n",
    "lon = np.unique(lon)\n",
    "lon.sort()\n",
    "lon_res = lon[1] - lon[0]\n",
    "lat_res = lat[1] - lat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165557df",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "variable = \"template_variable\" \n",
    "Variable = variable.title()\n",
    "vv_name= variable\n",
    "if vv_name == \"co2flux\":\n",
    "    vv_name = \"air-sea CO~2~ fluxes\"\n",
    "source = glob.glob(f\"../../matched/gridded/**/**/**_{variable}*.nc\")[0].split(\"/\")[-1].split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d20026",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "if source == \"nsbc\":\n",
    "    md(\"We used version 1.1 of the **North Sea Biogeochemical Climatology** (NSBC) to validate **sea surface template_variable**. NSBC is a monthly climatology that covers the region 47°-65°N and 15°W-15°E. The data is made up of observations over the period 1960-2014. For validation purposes we only used the level 3 data, which a gridded monthly climatology at a spatial resolution of 1/4°.  The data can be download from [NSBC](https://www.cen.uni-hamburg.de/en/icdc/data/ocean/nsbc.html).\")\n",
    "else:\n",
    "    if variable == \"poc\":\n",
    "        md(\"Model and observational POC were compared using data from the National Centre for Earth Observation (NCEO).\")\n",
    "        md(\"*Summary from NCEO*\")\n",
    "        md(\"The National Centre for Earth Observation (NCEO): Monthly global Particulate Organic Carbon (POC) dataset contains POC concentrations gridded on both sinusoidal (SIN) and geographic (GEO) grid projections at 4 km spatial resolution for 1997-2020. The POC dataset has been produced using the Ocean Colour Climate Change Initiative Remote Sensing Reflectance (Rrs) products, Version 4.2. The dataset includes the Rrs at 443 nm and 555 nm with pixel-by-pixel uncertainty estimates for each wavelength.\")\n",
    "        md(\"For more details on the algorithm and its validation, please see papers by Stramski et al. (2008) and Evers-King et al. (2017). Please note that the validation of the POC algorithm is a continuing process. To increase the accuracy of POC algorithms, further in situ POC data need to be collected with high spatial and temporal resolution.\")\n",
    "\n",
    "    if variable == \"doc\":\n",
    "        md(\"## Data Source: NCEO BICEP project DOC\")\n",
    "        md(\"Modelled DOC does not included the refactory component, which is typically 40 uM. This was added to the model data to make it comparable to the NCEO data.\")\n",
    "    \n",
    "    if source == \"ostia\":\n",
    "        md(\"Temperature was validated using the OSTIA sea surface temperature dataset. The validation was performed by comparing the modelled temperature with the OSTIA data for the same time and location. The OSTIA data was downloaded from the Copernicus Marine Environment Monitoring Service () catalogue. A description of the dataset is available [here](https://data.marine.copernicus.eu/product/SST_GLO_SST_L4_REP_OBSERVATIONS_010_011/description).\")\n",
    "    \n",
    "    if source == \"cobe2\":\n",
    "        md(f\"Temperature was validated using the COBE2 sea surface temperature dataset. The validation was performed by comparing the modelled temperature with the COBE2 data for the same time and location. The COBE2 data was downloaded from https://psl.noaa.gov/data/gridded/data.cobe2.html.\")\n",
    "        md(f\"Observational temperature is a monthly time series from 1850 with a spatial resolution of 1°x1°.\")\n",
    "\n",
    "md(f\"The model and observations were matched up as follows. First, the model dataset was cropped by a small amount to make sure cells close to the boundary were removed.\")\n",
    "\n",
    "md(\"The model was then regridded to the observational grid if the observational grid was coarser using nearest neighbour. Only grid cells with model and observational data were maintained.\")\n",
    "\n",
    "df_mapping = pd.read_csv(\"../../matched/mapping.csv\")\n",
    "model_variable = list(df_mapping.query(\"variable == @variable\").model_variable)[0]\n",
    "\n",
    "md(f\"The following model output was used to compare with observational **{variable}**: **{model_variable}**.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fa244",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"../../matched/gridded/**/**/**_{variable}*.nc\")\n",
    "if len(ff) != 1:\n",
    "    raise ValueError(\"Something is wrong with the file\")\n",
    "layer = os.path.basename(ff[0]).split(\"_\")[-1].replace(\".nc\", \"\")\n",
    "ds_model = nc.open_data(ff)\n",
    "ds_model.set_precision(\"F32\")\n",
    "ds_model.subset(variable = \"model\")\n",
    "ds_model.tmean(\"month\")\n",
    "ds_year = min(ds_model.years)\n",
    "ds_model.set_year(ds_year)\n",
    "ds_times = ds_model.times\n",
    "df_times = pd.DataFrame({\"year\":[x.year for x in ds_times]}).groupby(\"year\").size().reset_index()\n",
    "df_times.columns = [\"year\", \"count\"]\n",
    "years = list(df_times.query(\"count > 1\").year)\n",
    "ds_model.as_missing(0)\n",
    "# if variable is doc, add 40\n",
    "ds_model.run()\n",
    "ds_annual = ds_model.copy()\n",
    "ds_annual.tmean()\n",
    "# ds_annual.set_longnames({ds_annual.variables[0]: Variable})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b478825b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "### Baseline climatologies of template_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcec28",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"Climatologies of model and observational {layer} {vv_name} are shown in the two figures below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c20a2",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"../../matched/gridded/**/**/**_{variable}*.nc\")\n",
    "ds_obs = nc.open_data(ff)\n",
    "ds_obs.subset(variable = \"observation\")\n",
    "ds_obs.set_precision(\"F32\")\n",
    "ds_obs.tmean(\"month\")\n",
    "ds_obs.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10beac",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "## fix the units and names\n",
    "\n",
    "vars = [\n",
    "        \"ammonium\",\n",
    "        \"chlorophyll\",\n",
    "        \"nitrate\",\n",
    "        \"phosphate\",\n",
    "        \"oxygen\",\n",
    "        \"silicate\",\n",
    "        \"poc\",\n",
    "        \"doc\",\n",
    "    ]\n",
    "if variable in vars:\n",
    "    # set the units of obs to match model\n",
    "    ds_obs.set_units({ds_obs.variables[0]: ds_model.contents.unit[0]})\n",
    "    if variable not in [\"poc\", \"doc\"]:\n",
    "        # set the longnames of obs to match model\n",
    "        ds_obs.set_longnames({ds_obs.variables[0]: f\"Observed surface {variable} concentration\"})\n",
    "        ds_model.set_longnames({ds_model.variables[0]: f\"Modelled surface {variable} concentration\"})\n",
    "        ds_annual.set_longnames({ds_annual.variables[0]: f\"Modelled annual mean surface {variable} concentration\"})\n",
    "    else:\n",
    "        ds_obs.set_longnames({ds_obs.variables[0]: f\"Observed surface {variable.upper()} concentration\"})\n",
    "        ds_model.set_longnames({ds_model.variables[0]: f\"Modelled surface {variable.upper()} concentration\"})\n",
    "        ds_annual.set_longnames({ds_annual.variables[0]: f\"Modelled annual mean surface {variable.upper()} concentration\"})\n",
    "    if variable == \"temperature\":\n",
    "        ds_obs.set_longnames({ds_obs.variables[0]: \"Observed sea surface temperature\"})\n",
    "        ds_model.set_longnames({ds_model.variables[0]: \"Modelled sea surface temperature\"})\n",
    "        ds_annual.set_longnames({ds_annual.variables[0]: \"Modelled annual mean sea surface temperature\"})\n",
    "\n",
    "ds_obs.run()\n",
    "ds_model.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6308613",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b885730",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9db9d",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"## Can the model reproduce seasonality of {layer} {vv_name}?\")\n",
    "\n",
    "md(f\"The ability of the model to reproduce seasonality of {layer} {vv_name} was assessed by comparing the modelled and observed seasonal cycle of {vv_name}. First, we derive a monthly climatology for the model data. Then, we calculate the Pearson correlation coefficient between the modelled and observed {vv_name} at each grid cell. The Pearson correlation coefficient is a measure of the linear correlation between two variables. It has a value between -1 and 1, where 1 indicates a perfect positive linear correlation, 0 indicates no linear correlation, and -1 indicates a perfect negative linear correlation.\")\n",
    "\n",
    "md(\"Note: we are only assessing the ability of the model to reproduce the ability of the model to reproduce seasonal changes, not long-term trends.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4893bf1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d3c68",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"## Regional assessment of model performance for {layer} {vv_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a330779f",
   "metadata": {},
   "source": [
    "We assessed the regional performance of the model by comparing the model with observations from the following regions: Southern North Sea, Central North Sea, Northern North Sea, Channel, Skagerrak, Norwegian Trench, Shetland, Irish Shelf, Irish Sea, Celtic Sea, Armorican, Northern North East Atlantic, Southern North East Atlantic, Shelf, Ocean, Rosa, Locate Shelf, Deep Ocean.\n",
    "\n",
    "The regions considered are mapped below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d37725",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    df_mapped = (\n",
    "        ds_regions\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "        .melt(id_vars = [\"lon\", \"lat\"])\n",
    "        .dropna()\n",
    "        .merge(regions_contents.loc[:,[\"variable\", \"long_name\"]])\n",
    "        .drop(columns = [ \"value\"])\n",
    "    )\n",
    "    bad = [\"Rosa\", \"Locate Shelf\"]\n",
    "    df_mapped = df_mapped.query(\"long_name not in @bad\")\n",
    "    xlim = np.array([df_mapped.lon.min(), df_mapped.lon.max()])\n",
    "    ylim = np.array([df_mapped.lat.min(), df_mapped.lat.max()])\n",
    "    shape = gpd.read_file(f\"{data_dir}/mapping/TM_WORLD_BORDERS-0.3.shp\")\n",
    "\n",
    "    def fix_name(x):\n",
    "        x = x.replace(\"North East\", \"NE\")\n",
    "        x = x.replace(\"North \", \"N \")\n",
    "        if x == \"Channel\":\n",
    "            x = \"English Channel\"\n",
    "        return x\n",
    "\n",
    "    fix_name = np.vectorize(fix_name)\n",
    "\n",
    "\n",
    "    df_mapped.long_name = fix_name(df_mapped.long_name)\n",
    "\n",
    "\n",
    "    gg = (\n",
    "        ggplot( df_mapped)+\n",
    "         geom_tile(aes(x  = \"lon\",y =   \"lat\"))+\n",
    "        geom_map(shape, aes(\"LON\", \"LAT\"), fill = \"grey\", colour = \"grey\")+\n",
    "        coord_cartesian(xlim = xlim, ylim = ylim)+\n",
    "        scale_x_continuous(breaks = [-20, -10, 0, 10], labels = [\"20°W\", \"10°W\", \"0°\", \"10°E\"])+\n",
    "        scale_y_continuous(breaks = [40, 50, 60], labels = [\"40°N\", \"50°N\", \"60°N\"])+\n",
    "        theme_bw(base_size = 10)+\n",
    "        facet_wrap(\"~long_name\")+\n",
    "\n",
    "        theme(axis_title_x=element_blank(),\n",
    "                axis_title_y=element_blank())\n",
    "    )\n",
    "\n",
    "    gg = gg.draw()\n",
    "    gg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98248a",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"**Figure {i_figure}**: Regions used for validation of {layer} {vv_name}.\")\n",
    "i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8b492",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"Time series were constructed comparing the monthly mean of the spatial average {layer} {vv_name} in each region. The spatial average was calculated using the mean of all grid cells within each region, accounting for grid cell area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c28508",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    df_all = []\n",
    "    for vv in ds_regions.variables:\n",
    "        ds_rr = ds_regions.copy()\n",
    "        ds_rr.subset(variable = vv)\n",
    "        ds_rr.run()\n",
    "        ds_vv = ds_ts.copy()\n",
    "        time_name = [x for x in list(ds_vv.to_xarray().coords) if \"time\" in x][0]\n",
    "        ds_vv * ds_rr\n",
    "        ds_region = ds_vv.copy()\n",
    "        ds_vv.spatial_mean()\n",
    "        region = list(regions_contents.query(\"variable == @vv\").long_name)[0]\n",
    "        df_vv = (\n",
    "            ds_vv\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .melt(\"time\")\n",
    "            .assign(month = lambda x: x.time.dt.month)\n",
    "            .assign(region = vv)\n",
    "        )\n",
    "        df_all.append(df_vv)\n",
    "        ds_region.tmean()\n",
    "        df_region = (\n",
    "            ds_region\n",
    "            .to_dataframe()\n",
    "            .dropna()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"model\", \"observation\"]]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "    \n",
    "        del ds_rr, ds_vv, ds_region\n",
    "    df_all = pd.concat(df_all).dropna()\n",
    "        \n",
    "    df_all = (\n",
    "        df_all\n",
    "        .merge(df_mapped.loc[:,[\"long_name\", \"variable\"]].drop_duplicates().rename(columns = {\"variable\": \"region\"}))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e077b12",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    ylab = \"Spatial average \" + vv_name + \" (\"+ nc.static_plot.fix_label(ds_ts.contents.unit[0]) + \")\"\n",
    "    gg = (\n",
    "        ggplot(df_all)+\n",
    "        geom_line(aes(\"month\", \"value\", colour = \"variable\"))+\n",
    "        facet_wrap(\"long_name\")+\n",
    "        labs(y = ylab )+\n",
    "        labs(x = \"Month\")+\n",
    "        theme(legend_position = \"top\")+\n",
    "        scale_color_manual(values = [\"red\", \"blue\"])+\n",
    "        theme_bw(base_size = 10)+\n",
    "        labs(colour = \"\")+\n",
    "        scale_x_continuous(breaks = [1,4, 7, 10], labels = [\"Jan\", \"Apr\", \"Jul\", \"Oct\"]) +\n",
    "        theme(legend_position = \"top\") \n",
    "        \n",
    "    )\n",
    "    \n",
    "    gg = gg.draw()\n",
    "    gg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db278d68",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"**Figure {i_figure}**: Seasonal cycle of {layer} {vv_name} for model and observations for each region. The spatial average is taken over the region.\") \n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a92e0c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394e52e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"Can the model reproduce spatial patterns of {layer} {vv_name}?\")\n",
    "\n",
    "md(f\"The ability of the model to reproduce spatial patterns of {layer} {vv_name} was assessed by comparing the modelled and observed {vv_name} at each grid cell. We calculated the Pearson correlation coefficient between the modelled and observed {vv_name} at each grid cell. The Pearson correlation coefficient is a measure of the linear correlation between two variables. It has a value between -1 and 1, where 1 indicates a perfect positive linear correlation, 0 indicates no linear correlation, and -1 indicates a perfect negative linear correlation.\")\n",
    "md(\"This was carried out monthly and using the annual mean in each grid cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf4cb7",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"../../matched/gridded/**/**/**_{variable}*.nc\")\n",
    "if len(ff) != 1:\n",
    "    raise ValueError(\"Something is wrong with the file\")\n",
    "layer = os.path.basename(ff[0]).split(\"_\")[-1].replace(\".nc\", \"\")\n",
    "ds_cor = nc.open_data(ff)\n",
    "ds_cor.set_precision(\"F32\")\n",
    "ds_cor.tmean(\"month\")\n",
    "ds_cor.cor_space(\"model\", \"observation\")\n",
    "ds_cor_df = ds_cor.to_dataframe().reset_index()\n",
    "ds_cor_df = ds_cor_df.dropna()\n",
    "time_name = [x for x in list(ds_cor.to_xarray().coords) if \"time\" in x][0]\n",
    "# rename time in dataframe\n",
    "ds_cor_df.rename(columns = {time_name: \"time\"}, inplace = True)\n",
    "# extract the month\n",
    "ds_cor_df[\"month\"] = ds_cor_df.time.dt.month\n",
    "ds_cor_df = ds_cor_df.loc[:,[\"month\", \"cor\"]].drop_duplicates()\n",
    "# change month number to month name\n",
    "ds_cor_df[\"month\"] = ds_cor_df[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
    "# now do this annually\n",
    "ds_cor = nc.open_data(ff)\n",
    "ds_cor.set_precision(\"F32\")\n",
    "ds_cor.tmean(\"month\")\n",
    "ds_cor.tmean()\n",
    "ds_cor.cor_space(\"model\", \"observation\")\n",
    "ds_cor_df_annual = ds_cor.to_dataframe().reset_index()\n",
    "ds_cor_df_annual = ds_cor_df_annual.dropna()\n",
    "time_name = [x for x in list(ds_cor.to_xarray().coords) if \"time\" in x][0]\n",
    "# rename time in dataframe\n",
    "ds_cor_df_annual.rename(columns = {time_name: \"time\"}, inplace = True)\n",
    "# extract the month\n",
    "ds_cor_df_annual[\"month\"] = ds_cor_df_annual.time.dt.month\n",
    "ds_cor_df_annual = ds_cor_df_annual.loc[:,[\"month\", \"cor\"]].drop_duplicates()\n",
    "# output to csv\n",
    "ds_cor_df_annual = ds_cor_df_annual.assign(month = \"Annual mean\")\n",
    "# merge the two dataframes\n",
    "ds_cor_df = pd.concat([ds_cor_df_annual, ds_cor_df])\n",
    "# change month to period\n",
    "ds_cor_df.rename(columns = {\"month\": \"period\"}, inplace = True)\n",
    "# Give the columns more sensible names\n",
    "ds_cor_df.rename(columns = {\"cor\": \"Correlation coefficient\"}, inplace = True)\n",
    "ds_cor_df.rename(columns = {\"period\": \"Time period\"}, inplace = True)\n",
    "ds_cor_df.style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c398f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Table {i_table}**: Pearson correlation coefficient between modelled and observed {layer} {vv_name} at each grid cell. The correlation was calculated monthly and using the annual mean in each grid cell.\")\n",
    "i_table += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative distribution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81781e65",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"The ability of the model to reproduce the broad-scale statistical distribution of {layer} {vv_name} is assessed by comparing the cumulative distribution function (CDF) of the modelled and observed {vv_name}. The CDF is a function that maps the probability that a random variable is less than or equal to a given value. The CDF is calculated by counting the number of values less than or equal to a given value and dividing by the total number of values. The CDF is a non-parametric measure of the statistical distribution of a random variable. It is a more robust measure of the statistical distribution than the mean and standard deviation, which are sensitive to outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "ds = nc.open_data(f\"../../results/monthly_mean/monthlymean_{variable}.nc\")\n",
    "ds_regions = nc.open_data(f\"{data_dir}/amm7_val_subdomains.nc\")\n",
    "ds_regions.subset(variable = \"Shelf\")\n",
    "ds_regions.as_missing(0)\n",
    "ds_regions.regrid(ds)\n",
    "ds * ds_regions\n",
    "df = (\n",
    "    ds\n",
    "    .to_dataframe()\n",
    "    .dropna()\n",
    "    .reset_index()\n",
    "    )\n",
    "time_name = [x for x in df.columns if \"time\" in x][0]\n",
    "df.rename(columns = {time_name: \"time\"}, inplace = True)\n",
    "df = (\n",
    "    df\n",
    "    .assign(month = lambda x: x.time.dt.month)\n",
    "    .loc[:,[\"lon\", \"lat\", \"model\", \"observation\", \"month\"]]\n",
    "    .drop_duplicates()\n",
    "    )\n",
    "df = df.melt([\"lon\", \"lat\", \"month\"])\n",
    "units = ds.contents.unit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df -i units -i variable -w 10 -h 10 --units in -r 100\n",
    "library(tidyverse)\n",
    "library(ggridges)\n",
    "library(ggthemes)\n",
    "\n",
    "df <- df %>%\n",
    "    group_by(variable, month) %>%\n",
    "    # calculate 98th percentile of value\n",
    "    summarize(limit = quantile(value, 0.98)) %>%\n",
    "    inner_join(df) %>%\n",
    "    # filter to values below 98th percentile\n",
    "    filter(value < limit) %>%\n",
    "    # remove limit column\n",
    "    select(-limit)\n",
    "\n",
    "\n",
    "# ggplot(iris, aes(x = Sepal.Length, y = Species, group = Species)) + \n",
    "#   geom_density_ridges(fill = \"#00AFBB\")\n",
    "\n",
    "# df <- df %>%\n",
    "#     mutate(month = as.factor(month))\n",
    "# convert month to month name\n",
    "df$month <- month.name[df$month]\n",
    "# convert month to factor\n",
    "df$month <- as.factor(df$month)\n",
    "# ensure month is ordered\n",
    "df$month <- factor(df$month, levels = month.name)\n",
    "\n",
    "\n",
    "# edf plot\n",
    "\n",
    "ggplot(df, aes(x = value, colour = variable)) +\n",
    "    stat_ecdf()+\n",
    "    facet_wrap(~month)+\n",
    "    labs(y = \"Cumulative probability\", x = str_glue(\"{str_to_title(variable)} ({units})\"))+\n",
    "    theme_bw(base_size = 14)+\n",
    "    theme(legend.position = \"top\")+\n",
    "    labs(colour = NULL)+\n",
    "    scale_color_fivethirtyeight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Figure {i_figure}**: Empirical distribution function of {layer} {vv_name} for model and observations for each month. This compares the distributions on the shelf across the entire domain using grid cells with model-observation matchups.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faff526",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "time_series = False\n",
    "if regional:\n",
    "    ff = glob.glob(f\"../../matched/gridded/**/**/**_{variable}*.nc\")\n",
    "    ds_ts = nc.open_data(ff)\n",
    "    years = ds_ts.years\n",
    "    year_range = f\"{min(years)}-{max(years)}\"\n",
    "    if len(years) > 1:\n",
    "        mask_all(ds_ts)\n",
    "        ds_ts.tmean(\"year\")\n",
    "        ds_ts.run()\n",
    "        time_series = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b2cfc",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    md(f\"The ability of the model to reproduce mult-year trends in {layer} {vv_name} was assessed by comparing the modelled and observed time series of annual {vv_name} across each region.\")\n",
    "    md(f\"The figure below shows the average {vv_name} in each region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41838c",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    df_all = []\n",
    "    for vv in ds_regions.variables:\n",
    "        ds_rr = ds_regions.copy()\n",
    "        ds_rr.subset(variable = vv)\n",
    "        ds_rr.run()\n",
    "        ds_vv = ds_ts.copy()\n",
    "        ds_vv * ds_rr\n",
    "        ds_region = ds_vv.copy()\n",
    "        ds_vv.spatial_mean()\n",
    "        region = list(regions_contents.query(\"variable == @vv\").long_name)[0]\n",
    "        time_name = [x for x in list(ds_vv.to_xarray().coords) if \"time\" in x][0]\n",
    "        df_vv = (\n",
    "            ds_vv\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .melt(\"time\")\n",
    "            .assign(year = lambda x: x.time.dt.year)\n",
    "            .assign(region = vv)\n",
    "        )\n",
    "        df_all.append(df_vv)\n",
    "        ds_region.tmean()\n",
    "        df_region = (\n",
    "            ds_region\n",
    "            .to_dataframe()\n",
    "            .dropna()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"model\", \"observation\"]]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "    \n",
    "        del ds_rr, ds_vv, ds_region\n",
    "    df_all = pd.concat(df_all).dropna()\n",
    "        \n",
    "    df_all = (\n",
    "        df_all\n",
    "        .merge(df_mapped.loc[:,[\"long_name\", \"variable\"]].drop_duplicates().rename(columns = {\"variable\": \"region\"}))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfffd70",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    ylab = \"Spatial average \" + variable + \" (\"+ nc.static_plot.fix_label(ds_ts.contents.unit[0]) + \")\"\n",
    "    \n",
    "    gg = (\n",
    "        ggplot(df_all)+\n",
    "        geom_line(aes(\"year\", \"value\", colour = \"variable\"))+\n",
    "        facet_wrap(\"long_name\")+\n",
    "        labs(y = ylab )+\n",
    "        labs(x = \"Year\")+\n",
    "        theme(legend_position = \"top\")+\n",
    "        scale_color_manual(values = [\"red\", \"blue\"])+\n",
    "        theme_bw(base_size = 10)+\n",
    "        labs(colour = \"\")+\n",
    "        theme(legend_position = \"top\") \n",
    "        \n",
    "    )\n",
    "    \n",
    "    gg = gg.draw()\n",
    "    gg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda63af6",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    md(f\"**Figure {i_figure}**: Changes in {layer} {vv_name} for model and observations for each region for the period {year_range}. The spatial average is taken over the region.\") \n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280efcca",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cbb9fe",
   "metadata": {},
   "source": [
    "## Data citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8536f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if source == \"nsbc\":\n",
    "    md(\"Hinrichs,Iris; Gouretski,Viktor; Paetsch,Johannes; Emeis, Kay; Stammer, Detlef (2017). North Sea Biogeochemical Climatology (Version 1.1).\")\n",
    "    md(\"URL: https://www.cen.uni-hamburg.de/en/icdc/data/ocean/nsbc.html\")\n",
    "if variable == \"poc\":\n",
    "    md(\"Sathyendranath, S.; Kong, C.; Jackson, T. (2021): NCEO: Monthly global Particulate Organic Carbon (POC) (produced from the Ocean Colour Climate Change Initiative, Version 4.2 dataset). Centre for Environmental Data Analysis, 07 January 2021. doi:10.5285/ef09d81517a84979ac60329e4859f449. https://dx.doi.org/10.5285/ef09d81517a84979ac60329e4859f449\")\n",
    "    md(\"URL: https://catalogue.ceda.ac.uk/uuid/ef09d81517a84979ac60329e4859f449\")\n",
    "\n",
    "if source == \"ostia\":\n",
    "    md(\"Good, S.; Fiedler, E.; Mao, C.; Martin, M.J.; Maycock, A.; Reid, R.; Roberts-Jones, J.; Searle, T.; Waters, J.; While, J.; Worsfold, M. The Current Configuration of the OSTIA System for Operational Production of Foundation Sea Surface Temperature and Ice Concentration Analyses. Remote Sens. 2020, 12, 720, doi:10.3390/rs12040720\")\n",
    "    md(\"URL: https://data.marine.copernicus.eu/product/SST_GLO_SST_L4_REP_OBSERVATIONS_010_011/description\")\n",
    "\n",
    "if source == \"cobe2\":\n",
    "    md(\"COBE-SST 2 and Sea Ice data provided by the NOAA PSL, Boulder, Colorado, USA, from their website at https://psl.noaa.gov.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
