{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of point_layer point_variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# bin_value using function from r4ecology's github\n",
    "import numpy as np\n",
    "def bin_value(x, bin_res):\n",
    "    return np.floor((x + bin_res / 2) / bin_res + 0.5) * bin_res - bin_res / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "variable = \"point_variable\".lower()\n",
    "layer = \"point_layer\"\n",
    "# get the units. File inspection could be randomized in case people have put loose files in there...\n",
    "import glob\n",
    "df = pd.read_csv(\"../../matched/mapping.csv\")\n",
    "df = df.query(\"variable == @variable\")\n",
    "pattern = list(df.pattern)[0]\n",
    "# while True:\n",
    "#     i = 0\n",
    "#     patterns = pattern.split(\"/\")\n",
    "#     for x in patterns:\n",
    "#         if x == \"**\":\n",
    "#             break\n",
    "#         i+=1\n",
    "#     new_pattern = glob.glob(\"/\".join(patterns[0:i])+\"/\" + \"**\" )[-1].split(\"/\")[-1]\n",
    "#     patterns[i] = new_pattern\n",
    "#     pattern = \"/\".join(patterns)\n",
    "\n",
    "    \n",
    "#     if len([x for x in pattern.split(\"/\") if x == \"**\"]) == 0:\n",
    "#         break\n",
    "paths = pd.read_csv(glob.glob(f\"../../matched/point/**/{layer}/{variable}/paths.csv\")[0]).path\n",
    "\n",
    "for ff in paths:\n",
    "    try:\n",
    "        ds = nc.open_data(paths[0])\n",
    "        model_variable = list(df.model_variable)[0].split(\"+\")[0]\n",
    "        unit = list(ds.contents.query(\"variable == @model_variable\").unit)[0]\n",
    "        break\n",
    "    except:\n",
    "        pass\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"../../matched/point/**/{layer}/{variable}/*_{variable}.csv\")[0]\n",
    "vv_source = os.path.basename(ff).split(\"_\")[0]\n",
    "df = pd.read_csv(ff)\n",
    "if variable == \"ph\":\n",
    "    df = df.query(\"observation > 4\").reset_index(drop = True)\n",
    "# Danish part is always dubious\n",
    "df = df.query(\"lon < 9\")\n",
    "ds= nc.open_data(f\"{data_dir}/amm7_val_subdomains.nc\")\n",
    "ds.subset(variable = \"Shelf\")\n",
    "ds.as_missing(0)\n",
    "ds.regrid(df.loc[:,[\"lon\", \"lat\"]].drop_duplicates().reset_index(drop = True), \"nn\")\n",
    "df_grid = ds.to_dataframe().reset_index().dropna().drop_duplicates()\n",
    "df = df.merge(df_grid)\n",
    "df_locs = df.loc[:,[\"lon\", \"lat\"]].drop_duplicates()\n",
    "# bin to 0.01 resolution\n",
    "df_raw = df\n",
    "df[\"lon\"] = df[\"lon\"].apply(lambda x: bin_value(x, 0.5))\n",
    "df[\"lat\"] = df[\"lat\"].apply(lambda x: bin_value(x, 0.5))\n",
    "if variable != \"carbon\":\n",
    "    df = df.groupby([\"lon\", \"lat\", \"year\", \"month\"]).mean().reset_index()\n",
    "else:\n",
    "    df = df.groupby([\"lon\", \"lat\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "if variable not in [\"poc\", \"doc\", \"carbon\"]:\n",
    "\n",
    "    if layer == \"bottom\":\n",
    "        md(f\"Near-bottom values of {variable} were extracted from ICES bottle and CTD data.\")\n",
    "    else:\n",
    "        md(f\"Values from the top 5 m of the water column were extracted from ICES bottle and CTD data.\")\n",
    "\n",
    "if layer == \"bottom\":\n",
    "    md(f\"This data was extracted from vertical profiles. The near_bottom value was defined as the value closest to the bottom, that was within 5 m of the bottom. Bathymetry was estimated using GEBCO Bathymetry data.\")\n",
    "else:\n",
    "    md(f\"This data was extracted from vertical profiles. Values from the top 5 m were extracted from the database. This was compared with the model values from the surface level.\")\n",
    "\n",
    "md(f\"In total there were {len(df)} {layer} values extracted from the observational database.\")\n",
    "\n",
    "if layer == \"bottom\":\n",
    "    md(\"**Note:** this analysis has been restricted to observations on the shelf region.\")\n",
    "\n",
    "if variable in [\"carbon\"]:\n",
    "    md(\"Carbon data was compiled from multiple sources\")\n",
    "\n",
    "if variable == \"poc\":\n",
    "    md(\"Particulate organic carbon data was compiled from multiple sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# bottom 1% of observations\n",
    "bot_low = df.observation.quantile(0.001)\n",
    "df = df.query(f\"observation >= {bot_low}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_locs -i variable -i unit -w 1000 -h 1200\n",
    "library(tidyverse, warn.conflicts = FALSE)\n",
    "world_map <- map_data(\"world\")\n",
    "# get lon, lat limits from profile_mld\n",
    "\n",
    "xlim = c(min(df_locs$lon), max(df_locs$lon))\n",
    "ylim = c(min(df_locs$lat), max(df_locs$lat))\n",
    "\n",
    "\n",
    "\n",
    "gg <- df_locs %>%\n",
    "# final six months of the year\n",
    "    ggplot()+\n",
    "    geom_point(aes(lon, lat))+\n",
    "    theme_gray(base_size = 24)+\n",
    "    # add colour scale. Minimum zero, label 100, \">100\"\n",
    "    geom_polygon(data = world_map, aes(long, lat, group = group), fill = \"grey60\")+\n",
    "    coord_fixed(xlim = xlim, ylim = ylim, ratio = 1.5) \n",
    "\n",
    "# figure out if lon minimum is less than -10\n",
    "if( min(df_locs$lon) < -10 ){\n",
    "    # add sensible labels for longitude and latitude\n",
    "\n",
    "    gg <- gg +\n",
    "    scale_x_continuous(breaks = seq(-10, 5, 5), labels = c(\"10°W\", \"5°W\", \"0°\", \"5°E\"))+ \n",
    "    scale_y_continuous(breaks = seq(45, 60, 5), labels = c(\"45°N\", \"50°N\", \"55°N\", \"60°N\"))+\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "    # move legen\n",
    "\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Figure {i_figure}:** Map of {layer} {variable} observations from ICES.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R -i df -i variable -i unit -w 1000 -h 1200\n",
    "# calculate number of observations per month\n",
    "# figure out if \"month\" in df\n",
    "if(\"month\" %in% colnames(df)){\n",
    "\n",
    "df1 <- df %>%\n",
    "    group_by(lon, lat, month) %>%\n",
    "    summarise(observation = n()) %>%\n",
    "    ungroup()   \n",
    "\n",
    "# plot number of observations per month using plotnine and geom_bar\n",
    "\n",
    "# change month to month name\n",
    "df1$month <- factor(df1$month, levels = 1:12, labels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n",
    "\n",
    "gg <- df1 %>%\n",
    "    ggplot(aes(x = month, y = observation))+\n",
    "    theme_gray(base_size = 24)+\n",
    "    geom_bar(stat = \"identity\")+\n",
    "    labs(y = \"Number of observations\", x= \"\")\n",
    "\n",
    "gg\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Figure {i_figure}:** Number of {layer} observations per month for {variable}.\")\n",
    "i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df -i variable -i unit -i layer -w 1000 -h 1200\n",
    "#%%R -i df -i variable -i unit -w 1600 -h 1000\n",
    "if(\"month\" %in% colnames(df)){\n",
    "\n",
    "\n",
    "library(tidyverse, warn.conflicts = FALSE)\n",
    "world_map <- map_data(\"world\")\n",
    "# get lon, lat limits from profile_mld\n",
    "\n",
    "xlim = c(min(df$lon), max(df$lon))\n",
    "ylim = c(min(df$lat), max(df$lat))\n",
    "\n",
    "\n",
    "df <- df %>%\n",
    "    mutate(bias = model - observation) \n",
    "\n",
    "# calculate the absolate bias\n",
    "\n",
    "df1 <- df %>%\n",
    "    mutate(bias = abs(bias))\n",
    "# calculate the 98th percentile of the absolute bias\n",
    "bias_high <- df1$bias %>% quantile(0.98)\n",
    "# cap the bias to +/1 98th percentile\n",
    "df$bias[df$bias > bias_high] <- bias_high\n",
    "df$bias[df$bias < -bias_high] <- -bias_high\n",
    "\n",
    "\n",
    "# # convert month number to month in profile_mld\n",
    "df <- df %>%\n",
    "    arrange(month)\n",
    "df$month <- factor(df$month, levels = df$month, labels = month.abb[df$month])\n",
    "# df$month <- factor(df$month, labels = month.abb)\n",
    "\n",
    "title <- str_glue(\"Bias in {layer} {variable} ({unit})\")\n",
    "\n",
    "out = str_glue(\"../../results/{layer}/{variable}/{layer}_{variable}_bias.csv\")\n",
    "\n",
    "# # check directory exists for out\n",
    "if (!dir.exists(dirname(out))){\n",
    "    dir.create(dirname(out), recursive = TRUE)\n",
    "}\n",
    "df %>% write_csv(out)\n",
    "\n",
    "# df.to_csv(out, index = False)\n",
    "\n",
    "# export to csv\n",
    "\n",
    "\n",
    "\n",
    "gg <- df %>%\n",
    "# final six months of the year\n",
    "    ggplot()+\n",
    "    geom_raster(aes(lon, lat, fill = bias))+\n",
    "    facet_wrap(~month)+\n",
    "    theme_gray(base_size = 24)+\n",
    "    # add colour scale. Minimum zero, label 100, \">100\"\n",
    "    geom_polygon(data = world_map, aes(long, lat, group = group), fill = \"grey60\")+\n",
    "    coord_fixed(xlim = xlim, ylim = ylim, ratio = 1.5) +\n",
    "    # move legend to the top. Make it 3 cm wide\n",
    "    # move legend title to the bottom and centre it\n",
    "    scale_fill_gradient2(low = \"blue\", high = \"red\",\n",
    "                       guide = guide_colorbar(title.position = \"bottom\", title.hjust = 0.5, title.theme = element_text(angle = 0, size = 20, family = \"Helvetica\"))\n",
    "  )+\n",
    "    theme(\n",
    "    legend.position = \"bottom\", legend.direction = \"horizontal\", legend.box = \"horizontal\", legend.key.width = unit(6.0, \"cm\"),\n",
    "    legend.key.height = unit(1.0, \"cm\"))+\n",
    "    # set the legend title to bias\n",
    "    labs(fill = title)\n",
    "\n",
    "# figure out if lon minimum is less than -10\n",
    "if( min(df$lon) < -10 ){\n",
    "    # add sensible labels for longitude and latitude\n",
    "\n",
    "    gg <- gg +\n",
    "    scale_x_continuous(breaks = seq(-10, 5, 5), labels = c(\"10°W\", \"5°W\", \"0°\", \"5°E\"))+ \n",
    "    scale_y_continuous(breaks = seq(45, 60, 5), labels = c(\"45°N\", \"50°N\", \"55°N\", \"60°N\"))+\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "    # move legen\n",
    "\n",
    "gg\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if variable not in [\"carbon\"]:\n",
    "    md(f\"**Figure {i_figure}**: Bias in {layer} {variable}. The bias is calculated as model - observation. The colour scale is from blue (negative bias) to red (positive bias). The colour scale is capped at the 98th percentile of the absolute bias. This is to avoid a few extreme outliers from dominating the colour scale. **Note:** values have been binned and averaged to 0.5 degree resolution.\") \n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_raw -i variable -i unit -w 1000 -h 1200\n",
    "#%%R -i df -i variable -i unit -w 1600 -h 1000\n",
    "if(\"month\" %in% colnames(df)){\n",
    "\n",
    "\n",
    "library(tidyverse, warn.conflicts = FALSE)\n",
    "\n",
    "# # convert month number to month in profile_mld\n",
    "df <- df_raw %>%\n",
    "    arrange(month)\n",
    "# df$month <- factor(df$month, labels = month.abb)\n",
    "\n",
    "x_lab <- str_glue(\"Model {variable} ({unit})\")\n",
    "y_lab <- str_glue(\"Observed {variable} ({unit})\")\n",
    "\n",
    "\n",
    "gg <- df %>%\n",
    "# final six months of the year\n",
    "    ggplot()+\n",
    "    geom_point(aes(model, observation))+\n",
    "    facet_wrap(~month)+\n",
    "    theme_gray(base_size = 24)+\n",
    "    labs(fill = title)+\n",
    "    geom_abline()+\n",
    "    geom_smooth(aes(model, observation), method = \"gam\")+\n",
    "    labs(x = x_lab, y = y_lab)\n",
    "    # move legen\n",
    "\n",
    "gg\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if variable not in [\"carbon\"]:\n",
    "    md(f\"**Figure {i_figure}**: Model vs observed {variable} for {layer} observations. The model is the ICES model and the observations are from ICES. The line is a GAM fit to the data. The data has been binned to 0.5 degree resolution.\")\n",
    "    i_figure = i_figure + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_raw -i variable -i unit -w 1000 -h 1200\n",
    "#%%R -i df -i variable -i unit -w 1600 -h 1000\n",
    "\n",
    "library(tidyverse, warn.conflicts = FALSE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_lab <- str_glue(\"Model {variable} ({unit})\")\n",
    "y_lab <- str_glue(\"Observed {variable} ({unit})\")\n",
    "\n",
    "\n",
    "gg <- df %>%\n",
    "# final six months of the year\n",
    "    ggplot()+\n",
    "    geom_point(aes(model, observation))+\n",
    "    theme_gray(base_size = 24)+\n",
    "    labs(fill = title)+\n",
    "    geom_abline()+\n",
    "    geom_smooth(aes(model, observation), method = \"gam\")+\n",
    "    labs(x = x_lab, y = y_lab)\n",
    "    # move legen\n",
    "\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Figure {i_figure}**: Model vs observed {variable} for {layer} values. The observations are from ICES bottle and CTD data. 5 degree resolution. The line is a GAM fit to the data. The shaded area is the 95% confidence interval of the GAM fit.\")\n",
    "i_figure += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"The overall ability of the model to predict the observed {variable} was assessed by calculating the average bias, the root mean square error (RMSE) and the correlation coefficient (R). The bias was calculated as the model value minus the observed value. The RMSE was calculated as the square root of the mean squared error. The correlation coefficient was calculated as the Pearson correlation coefficient between the model and observed values.\") \n",
    "md(f\"This was calculated for each month and for the entire dataset. The results are shown in the tables below.\")\n",
    "md(f\"This is calculated in two separate ways. First, we use the raw model and observed values. Second, we use data that was averaged to 0.5 to 0.5 bins to account for spatial bias.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if variable not in [\"carbon\"]:\n",
    "    df_bias = (\n",
    "        df_raw\n",
    "        .assign(bias = lambda x: x.model - x.observation)\n",
    "        .groupby(\"month\")\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .loc[:,[\"month\", \"bias\"]]\n",
    "        # convert month number to name\n",
    "        .assign(month = lambda x: x.month.apply(lambda y: calendar.month_abbr[y]))\n",
    "    )\n",
    "    # add average bias to df_bias as a separate row\n",
    "    annual_bias = df_raw.model.mean() - df_raw.observation.mean() \n",
    "    df_bias = pd.concat([df_bias, pd.DataFrame({\"month\": [\"All\"], \"bias\": [annual_bias]})])\n",
    "\n",
    "    # move the final row to the top\n",
    "    df_bias = pd.concat([df_bias.iloc[[-1]], df_bias.iloc[:-1]])\n",
    "else:\n",
    "    # only want annual\n",
    "    df_bias = pd.DataFrame({\"month\": [\"All\"], \"bias\": [df_raw.model.mean() - df_raw.observation.mean()]})\n",
    "if variable not in [\"carbon\"]:\n",
    "    # now create an rmse dataframe\n",
    "    df_rmse = (\n",
    "        df_raw\n",
    "        .assign(month = lambda x: x.month.apply(lambda y: calendar.month_abbr[y]))\n",
    "        .groupby(\"month\")\n",
    "        .apply(lambda x: np.sqrt((x.model - x.observation).pow(2).mean()))\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"rmse\"})\n",
    "    )\n",
    "    # add average rmse to df_rmse as a separate row\n",
    "    annual_rmse = np.sqrt(((df_raw.model - df_raw.observation).pow(2)).mean())\n",
    "    df_rmse = pd.concat([df_rmse, pd.DataFrame({\"month\": [\"All\"], \"rmse\": [annual_rmse]})])\n",
    "    # move the final row to the top\n",
    "    df_rmse = pd.concat([df_rmse.iloc[[-1]], df_rmse.iloc[:-1]])\n",
    "else:\n",
    "    # only want annual\n",
    "    df_rmse = pd.DataFrame({\"month\": [\"All\"], \"rmse\": [np.sqrt(((df_raw.model - df_raw.observation).pow(2)).mean())]})\n",
    "# rename the month column to Month\n",
    "# merge the two dataframes\n",
    "df_table = copy.deepcopy(df_bias).merge(df_rmse)\n",
    "df_table = df_table.round(2)\n",
    "# create df_corr\n",
    "if variable not in [\"carbon\"]:\n",
    "    df_corr = (\n",
    "        df_raw\n",
    "        .groupby(\"month\")\n",
    "        .apply(lambda x: x.model.corr(x.observation))\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"correlation\"})\n",
    "        .assign(month = lambda x: x.month.apply(lambda y: calendar.month_abbr[y]))\n",
    "    )\n",
    "    # add average correlation to df_corr as a separate row\n",
    "    # calculate annual correlation using all data\n",
    "    annual_corr = df_raw.model.corr(df_raw.observation)\n",
    "    df_corr = pd.concat([df_corr, pd.DataFrame({\"month\": [\"All\"], \"correlation\": [annual_corr]})])\n",
    "    # df_corr = df_corr.append({\"month\": \"All\", \"correlation\": annual_corr}, ignore_index=True)\n",
    "\n",
    "    # move the final row to the top\n",
    "    df_corr = pd.concat([df_corr.iloc[[-1]], df_corr.iloc[:-1]])\n",
    "else:\n",
    "    # only want annual\n",
    "    df_corr = pd.DataFrame({\"month\": [\"All\"], \"correlation\": [df_raw.model.corr(df_raw.observation)]})\n",
    "df_table = df_table.merge(df_corr)\n",
    "df_table = df_table.round(2)\n",
    "df_table = df_table.rename(columns={\"month\": \"Month\", \"bias\": \"Bias\", \"rmse\": \"RMSE\", \"correlation\": \"Correlation\"})\n",
    "df_table = df_table[[\"Month\", \"Bias\", \"RMSE\", \"Correlation\"]]\n",
    "# change Month to Period\n",
    "df_table = df_table.rename(columns={\"Month\": \"Time period\"})\n",
    "\n",
    "if variable not in [\"carbon\"]:\n",
    "    # add commas to bias and rmse\n",
    "    df_number = df_raw.groupby(\"month\").count().reset_index().loc[:,[\"month\", \"observation\"]]\n",
    "# convert month number to name\n",
    "    df_number[\"month\"] = df_number[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
    "    df_number = df_number.rename(columns={\"month\": \"Time period\", \"observation\": \"Number of observations\"})\n",
    "else:\n",
    "    df_number = pd.DataFrame({\"Time period\": [\"All\"], \"Number of observations\": [len(df_raw)]})\n",
    "\n",
    "# add total number of observations\n",
    "annual_number = len(df_raw)\n",
    "if variable not in [\"carbon\"]:\n",
    "    df_number = pd.concat([df_number, pd.DataFrame({\"Time period\": [\"All\"], \"Number of observations\": [annual_number]})])\n",
    "# df_number = df_number.append({\"Time period\": \"All\", \"Number of observations\": annual_number}, ignore_index=True)\n",
    "df_table = df_table.merge(df_number)\n",
    "\n",
    "# include commas in the number of observations\n",
    "df_table[\"Number of observations\"] = df_table[\"Number of observations\"].apply(lambda x: \"{:,}\".format(x))\n",
    "\n",
    "df_table.style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Table {i_table}:** Average bias and root-mean square error in {layer} {variable} for each month using the raw ICES data. The bias is calculated as model - observation. The average bias is calculated as the mean of the monthly biases.\")\n",
    "i_table += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if variable not in [\"carbon\"]:\n",
    "    df_bias = (\n",
    "        df\n",
    "        .assign(bias = lambda x: x.model - x.observation)\n",
    "        .groupby(\"month\")\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .loc[:,[\"month\", \"bias\"]]\n",
    "        # convert month number to name\n",
    "        .assign(month = lambda x: x.month.apply(lambda y: calendar.month_abbr[y]))\n",
    "    )\n",
    "    # add average bias to df_bias as a separate row\n",
    "    annual_bias = df.model.mean() - df.observation.mean() \n",
    "    df_bias = pd.concat([df_bias, pd.DataFrame({\"month\": [\"All\"], \"bias\": [annual_bias]})])\n",
    "\n",
    "    # move the final row to the top\n",
    "    df_bias = pd.concat([df_bias.iloc[[-1]], df_bias.iloc[:-1]])\n",
    "else:\n",
    "    # only want annual\n",
    "    df_bias = pd.DataFrame({\"month\": [\"All\"], \"bias\": [df.model.mean() - df.observation.mean()]})\n",
    "if variable not in [\"carbon\"]:\n",
    "    # now create an rmse dataframe\n",
    "    df_rmse = (\n",
    "        df\n",
    "        .assign(month = lambda x: x.month.apply(lambda y: calendar.month_abbr[y]))\n",
    "        .groupby(\"month\")\n",
    "        .apply(lambda x: np.sqrt((x.model - x.observation).pow(2).mean()))\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"rmse\"})\n",
    "    )\n",
    "    # add average rmse to df_rmse as a separate row\n",
    "    annual_rmse = np.sqrt(((df.model - df.observation).pow(2)).mean())\n",
    "    df_rmse = pd.concat([df_rmse, pd.DataFrame({\"month\": [\"All\"], \"rmse\": [annual_rmse]})])\n",
    "    # move the final row to the top\n",
    "    df_rmse = pd.concat([df_rmse.iloc[[-1]], df_rmse.iloc[:-1]])\n",
    "else:\n",
    "    # only want annual\n",
    "    df_rmse = pd.DataFrame({\"month\": [\"All\"], \"rmse\": [np.sqrt(((df.model - df.observation).pow(2)).mean())]})\n",
    "# rename the month column to Month\n",
    "# merge the two dataframes\n",
    "df_table = copy.deepcopy(df_bias).merge(df_rmse)\n",
    "df_table = df_table.round(2)\n",
    "# create df_corr\n",
    "if variable not in [\"carbon\"]:\n",
    "    df_corr = (\n",
    "        df\n",
    "        .groupby(\"month\")\n",
    "        .apply(lambda x: x.model.corr(x.observation))\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"correlation\"})\n",
    "        .assign(month = lambda x: x.month.apply(lambda y: calendar.month_abbr[y]))\n",
    "    )\n",
    "    # add average correlation to df_corr as a separate row\n",
    "    # calculate annual correlation using all data\n",
    "    annual_corr = df.model.corr(df.observation)\n",
    "    df_corr = pd.concat([df_corr, pd.DataFrame({\"month\": [\"All\"], \"correlation\": [annual_corr]})])\n",
    "    # df_corr = df_corr.append({\"month\": \"All\", \"correlation\": annual_corr}, ignore_index=True)\n",
    "\n",
    "    # move the final row to the top\n",
    "    df_corr = pd.concat([df_corr.iloc[[-1]], df_corr.iloc[:-1]])\n",
    "else:\n",
    "    # only want annual\n",
    "    df_corr = pd.DataFrame({\"month\": [\"All\"], \"correlation\": [df.model.corr(df.observation)]})\n",
    "df_table = df_table.merge(df_corr)\n",
    "df_table = df_table.round(2)\n",
    "df_table = df_table.rename(columns={\"month\": \"Month\", \"bias\": \"Bias\", \"rmse\": \"RMSE\", \"correlation\": \"Correlation\"})\n",
    "df_table = df_table[[\"Month\", \"Bias\", \"RMSE\", \"Correlation\"]]\n",
    "# change Month to Period\n",
    "df_table = df_table.rename(columns={\"Month\": \"Time period\"})\n",
    "\n",
    "if variable not in [\"carbon\"]:\n",
    "    # add commas to bias and rmse\n",
    "    df_number = df.groupby(\"month\").count().reset_index().loc[:,[\"month\", \"observation\"]]\n",
    "# convert month number to name\n",
    "    df_number[\"month\"] = df_number[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
    "    df_number = df_number.rename(columns={\"month\": \"Time period\", \"observation\": \"Number of observations\"})\n",
    "else:\n",
    "    df_number = pd.DataFrame({\"Time period\": [\"All\"], \"Number of observations\": [len(df)]})\n",
    "\n",
    "# add total number of observations\n",
    "annual_number = len(df)\n",
    "if variable not in [\"carbon\"]:\n",
    "    df_number = pd.concat([df_number, pd.DataFrame({\"Time period\": [\"All\"], \"Number of observations\": [annual_number]})])\n",
    "# df_number = df_number.append({\"Time period\": \"All\", \"Number of observations\": annual_number}, ignore_index=True)\n",
    "df_table = df_table.merge(df_number)\n",
    "\n",
    "# include commas in the number of observations\n",
    "df_table[\"Number of observations\"] = df_table[\"Number of observations\"].apply(lambda x: \"{:,}\".format(x))\n",
    "\n",
    "df_table.style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Table {i_table}:** Average bias and root-mean square error in {layer} {variable} for each month using binned ICES data. ICES data was averaged in each 0.5 by 0.5 degree cell in each year and month. The bias is calculated as model - observation. The average bias is calculated as the mean of the monthly biases.\")\n",
    "i_table += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regresion analysis of model vs observed point_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"A linear regression analysis of modelled and observed {variable} was performed. The modelled {variable} was used as the independent variable and the observed {variable} was used as the dependent variable. The results are shown in the table below.\")\n",
    "\n",
    "md(\"The regression was carried out using the Python package statsmodels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# do a linear regression of model vs observed in df\n",
    "X = df.model.values\n",
    "Y = df.observation.values\n",
    "# linear regression using statsmodels\n",
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X)\n",
    "# make X and Y random numbers between 0 and 1\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X).fit()\n",
    "# get the slope and intercept\n",
    "intercept, slope = model.params\n",
    "# calculate the r squared\n",
    "r2 = model.rsquared\n",
    "# calculate the p value of the slope\n",
    "p = model.f_pvalue\n",
    "\n",
    "p = model.f_pvalue\n",
    "# put that in a dataframe\n",
    "df_stats = pd.DataFrame({\"Slope\": slope, \"Intercept\": intercept, \"R2\": r2, \"P\": p}, index = [\"All\"]).assign(Period = \"All\")\n",
    "# do this month by month append to df_stats\n",
    "\n",
    "for month in range(1, 13):\n",
    "    try:\n",
    "        X = df.query(\"month == @month\").model.values\n",
    "        Y = df.query(\"month == @month\").observation.values\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.OLS(Y, X).fit()\n",
    "        intercept, slope = model.params\n",
    "        r2 = model.rsquared\n",
    "        p = model.f_pvalue\n",
    "        df_stats = pd.concat([df_stats, pd.DataFrame({\"Slope\": slope, \"Intercept\": intercept, \"R2\": r2, \"P\": p}, index = [month]).assign(Period = month)])\n",
    "        df_stats.loc[df_stats.index[-1], \"Period\"] = calendar.month_abbr[month]\n",
    "    except:\n",
    "        pass\n",
    "# sort period appropriately, so All is first then ordered by month\n",
    "df_stats[\"Period\"] = pd.Categorical(df_stats[\"Period\"], [calendar.month_abbr[x] for x in range(1, 13)] + [\"All\"])\n",
    "# round p-value to 3 dp\n",
    "df_stats[\"P\"] = df_stats[\"P\"].round(5)\n",
    "# change P to p-value\n",
    "df_stats = df_stats.rename(columns={\"P\": \"p-value\"})\n",
    "# put Period first\n",
    "df_stats = df_stats[[\"Period\", \"Slope\", \"Intercept\", \"R2\", \"p-value\"]]\n",
    "# \n",
    "\n",
    "df_stats.style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "## Data citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if variable == \"poc\":\n",
    "    md(\"Boss, Emmanuel; Picheral, Marc; Searson, Sarah; Le Goff, Hervé; Reverdin, Gilles; Leeuw, Thomas; Chase, Alison P; Bricaud, Annick; Kolber, Zbigniew S; Taillandier, V; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Underway surface water data during the Tara Oceans expedition in 2009-2012 [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.873566, In: Boss, Emmanuel; Picheral, Marc; Searson, Sarah; Marec, Claudie; Le Goff, Hervé; Reverdin, Gilles; Leeuw, Thomas; Chase, Alison P; Anderson, Leif G; Gattuso, Jean-Pierre; Pino, Diana Ruiz; Padín, Xose Antonio; Grondin, Pierre-Luc; Matuoka, Atsushi; Babin, Marcel; Bricaud, Annick; Kolber, Zbigniew S; Taillandier, V; Hafez, Mark; Chekalyuk, Alexander; Pesant, Stephane; Météo France; Tara Oceans Consortium, Coordinators (2017): Harmonised data from underway navigation, meteorology and surface water measurements during the Tara Oceans expedition in 2009-2013 [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.873592\")\n",
    "    md(\"Röttgers, Rüdiger; Bi, Shun; Burmester, Henning; Heymann, Kerstin; Hieronymi, Martin; Krasemann, Hajo; Schönfeld, Wolfgang (2023): Water inherent optical properties and concentrations of water constituents from the German Bight and adjacent regions: concentrations and auxiliary data [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.950767, In: Röttgers, Rüdiger; Bi, Shun; Burmester, Henning; Heymann, Kerstin; Hieronymi, Martin; Krasemann, Hajo; Schönfeld, Wolfgang (2023): Water inherent optical properties and concentrations of water constituents from the German Bight and adjacent regions [dataset bundled publication]. PANGAEA, https://doi.org/10.1594/PANGAEA.950774)\")\n",
    "    md(\"Loisel, Hubert; Duforêt-Gaurier, Lucile; Tran, Trung Kien; Jorge, Daniel S F; Steinmetz, Francois; Mangin, Antoine; Bretagnon, Marine; d'Andon, Odile (2023): Database (DSM) of in situPOC, SPM and Rrs collected between 1997 and 2018 [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.960962\")\n",
    "    md(\"Lønborg, Christian; Carreira, Cátia; Abril, Gwenael; Agustí, Susana; Amaral, Valentina; Andersson, Agneta; Arístegui, Javier; Bhadury, Punyasloke; Bif, Mariana B; Borges, Alberto Vieira; Bouillon, Steven; Calleja, Maria Ll; Cotovicz, Luiz C Jr; Cozzi, Stefano; Doval, Maryló; Duarte, Carlos Manuel; Eyre, Bradley D; Fichot, Cedric; García-Martín, Elena; Garzon-Garcia, Alexandra; Giani, Michele; Gonçalves-Araujo, Rafael; Gruber, Renee K; Hansell, Dennis A; Hashihama, Fuminori; He, Ding; Holding, Johnna M; Hunter, William Ross; Ibánhez, J Severino; Ibello, Valeria; Jiang, Shan; Kim, Guebuem; Klun, Katja; Kowalczuk, Piotr; Kubo, Atsushi; Lee, Choon Weng; Lopes, Claudia B; Maggioni, Federica; Magni, Paolo; Marrasé, Celia; Martin, Patrick; McCallister, S Leigh; McCallum, Rosh; M Medeiros, Patricia; G Morán, Xosé Anxelu; Muller-Karger, Frank; Myers-Pigg, Allison; Norli, Marit; Oakes, Joanne M; Osterholz, Helena; Park, Hyekyung; Lund Paulsen, Maria; Rosentreter, Judith A; Ross, Jeff; Rueda-Roa, Digna; Santinelli, Chiara; Shen, Yuan; Teira, Eva; Tinta, Tinkara; Uher, Guenther; Wakita, Masahide; Ward, Nicholas D; Watanabe, Kenta; Xin, Yu; Yamashita, Youhei; Yang, Liyang; Yeo, Jacob; Yuan, Huamao; Zheng, Qiang; Álvarez‐Salgado, Xosé Antón (2023): A global database of dissolved organic matter (DOM) concentration measurements in coastal waters (CoastDOM v.1) [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.964012\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if vv_source == \"ices\":\n",
    "    md(f\"Data for {variable} was downloaded from the ICES website on 3rd March 2023. The data is available from [ICES](https://data.ices.dk/view-map).\") \n",
    "    md(\"A minimum requirement citation would include the following: “ICES Data Portal, Dataset on Ocean Hydrochemistry, 2023. ICES, Copenhagen”\")\n",
    "\n",
    "    md(\"Extended citation: ICES Data Portal, Dataset on Ocean HydroChemistry, Extracted March 3, 2023. ICES, Copenhagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if variable == \"carbon\":\n",
    "    md('Diesing, Markus, Terje Thorsnes, and Lilja Rún Bjarnadóttir. \"Organic carbon densities and accumulation rates in surface sediments of the North Sea and Skagerrak.\" Biogeosciences 18.6 (2021): 2139-2160.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
