{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# domain_title summary statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_start\n",
    "shelf = shelf_mask\n",
    "from IPython.display import Markdown as md\n",
    "import glob\n",
    "import nctoolkit as nc\n",
    "from mask import mask_all, mask_shelf\n",
    "from ecoval import tidy_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "show_map = False\n",
    "\n",
    "if len([x for x in glob.glob(\"*.ipynb\") if \"summary_shelf\" in x]) > 0:\n",
    "    ds_regions = nc.open_data(f\"{data_dir}/amm7_val_subdomains.nc\")\n",
    "    ds_regions.subset(variables = [\"Shelf\", \"Ocean\"])\n",
    "    ds_regions.sum_all()\n",
    "    ds_regions.as_missing(0)\n",
    "    if shelf:\n",
    "        mask_shelf(ds_regions)\n",
    "    \n",
    "    ds_plot = ds_regions.pub_plot(legend_position=None, land = \"lightgrey\")\n",
    "    show_map = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if show_map:\n",
    "    if shelf:\n",
    "        md(f\"**Figure {i_figure}**: Map of the shelf area used for the evaluation.\")\n",
    "    else:\n",
    "        md(f\"**Figure {i_figure}**: Map of the ocean area used for the evaluation.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taylor diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import nctoolkit as nc\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display_markdown \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from plotnine import *\n",
    "import numpy as np\n",
    "import os\n",
    "import glob as glob\n",
    "from mask import mask_all, mask_shelf\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "i_table = 1\n",
    "stamp = nc.session_info[\"stamp\"]\n",
    "out = \".trackers/\" + stamp\n",
    "if not os.path.exists(\".trackers\"):\n",
    "    os.makedirs(\".trackers\")\n",
    "# save out as empty file\n",
    "with open(out, 'w') as f:\n",
    "    f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ensemble = nc.create_ensemble(\"../../results/annual_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "df_taylor = []\n",
    "for ff in ensemble:\n",
    "    variable = os.path.basename(ff).split(\"_\")[1].replace(\".nc\", \"\")\n",
    "    ds_ff = nc.open_data(ff)\n",
    "    if True:\n",
    "        mask_shelf(ds_ff)\n",
    "    else:\n",
    "        mask_all(ds_ff)\n",
    "\n",
    "    df_ff = ds_ff.to_dataframe().reset_index()\n",
    "    lon_name = [df_ff.columns[i] for i in range(len(df_ff.columns)) if \"lon\" in df_ff.columns[i]][0]\n",
    "    lat_name = [df_ff.columns[i] for i in range(len(df_ff.columns)) if \"lat\" in df_ff.columns[i]][0]\n",
    "    df_taylor.append(\n",
    "        df_ff\n",
    "        .loc[:,[lon_name, lat_name, \"model\", \"observation\"]]\n",
    "        .dropna()\n",
    "        .assign(variable = variable)\n",
    "    )\n",
    "df_taylor = pd.concat(df_taylor).reset_index(drop=True)\n",
    "\n",
    "# fix name of variable\n",
    "df_taylor = (\n",
    "    df_taylor\n",
    "    .assign(variable = lambda x: x[\"variable\"].apply(tidy_name))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_taylor\n",
    "\n",
    "library(plotrix, warn.conflicts = FALSE)\n",
    "library(dplyr, warn.conflicts = FALSE)\n",
    "\n",
    "# get unique variable from df_taylor\n",
    "\n",
    "variables <- df_taylor %>%\n",
    "    group_by(variable) %>%\n",
    "    summarize(nsd = sd(model)/sd(observation))  %>%\n",
    "    arrange(desc(nsd)) %>%\n",
    "    pull(variable) \n",
    "\n",
    "pch = 1:length(variables)\n",
    "col = rainbow(length(variables))\n",
    "\n",
    "r_min <- df_taylor %>%\n",
    "    group_by(variable) %>%\n",
    "    summarise(r = cor(observation, model, use = \"complete.obs\")) %>%\n",
    "    summarize(r = min(r)) %>%\n",
    "    pull(r)\n",
    "\n",
    "pos_cor = r_min >= -0.1\n",
    "\n",
    "i <- 1\n",
    "for (vv in variables){\n",
    "\n",
    "    df_vv <- df_taylor %>%\n",
    "        filter(variable == vv)\n",
    "    if(i == 1){\n",
    "        plot_size <- df_vv %>%\n",
    "        # get the standard deviation of all\n",
    "        summarize(nsd = sd(model)/sd(observation)) %>%\n",
    "        pull(nsd)\n",
    "\n",
    "    }\n",
    "\n",
    "    if (i == 1){\n",
    "        taylor.diagram(df_vv$observation, df_vv$model, pch = pch[i], col = col[i], add = FALSE, normalize = TRUE,\n",
    "        pos.cor = pos_cor, main = NULL\n",
    "\n",
    "        )\n",
    "    } else {\n",
    "        taylor.diagram(df_vv$observation, df_vv$model, pch = pch[i], col = col[i], add = TRUE, normalize = TRUE,\n",
    "        pos.cor = pos_cor\n",
    "\n",
    "        )\n",
    "    }\n",
    "\n",
    "i <- i + 1\n",
    "}\n",
    "\n",
    "legend( plot_size * 1.3, plot_size * 1.9, legend = variables, pch = pch, col = col, bty = \"n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "variables = df_taylor.variable.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Figure {i_figure}**: Taylor diagram for annual mean of {', '.join(variables)}. This diagram compares climatological annual averages of the model and observations across the model's spatial domain. Standard devaiation is normalized by the standard deviation of the observations, and a standard deviation below 1 indicates that the model is less variable than the observations. Note: This figure summarizes the overall ability of the model to reproduce climatological spatial patterns, and it does not represent temporal performance.\") \n",
    "i_figure += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "df_bias= []\n",
    "for ff in ensemble:\n",
    "    variable = os.path.basename(ff).split(\"_\")[1].replace(\".nc\", \"\").title()\n",
    "    if variable.lower() == \"sst\":\n",
    "        variable = \"SST\"\n",
    "    ds_ff = nc.open_data(ff)\n",
    "    ds_ff.set_precision(\"F32\")\n",
    "    if True:\n",
    "        mask_shelf(ds_ff)\n",
    "    else:\n",
    "        mask_all(ds_ff)\n",
    "    ds_ff.assign(bias = lambda x: x.model - x.observation)\n",
    "    ds_ff.spatial_mean()\n",
    "    bias = ds_ff.to_dataframe().reset_index().bias.values[0]\n",
    "    unit = ds_ff.contents.unit[0]\n",
    "    name = variable \n",
    "    model = ds_ff.to_dataframe().reset_index().model.values[0]\n",
    "    observation = ds_ff.to_dataframe().reset_index().observation.values[0]\n",
    "    df_bias.append(pd.DataFrame({\"Variable\": [name], \"Modelled spatial mean\": [model], \"Observational spatial mean\":[observation], \"Model bias\": [bias], \"Unit\": [unit]}))\n",
    "df_bias = pd.concat(df_bias).reset_index(drop=True)\n",
    "df_bias = df_bias.assign(percentage_bias = lambda x: x[\"Model bias\"]/x[\"Observational spatial mean\"]*100)\n",
    "df_bias.loc[df_bias.Variable == \"temperature\", \"percentage_bias\"] = np.nan\n",
    "df_bias.columns = [\"Variable\", \"Modelled spatial mean\", \"Observational spatial mean\", \"Model bias\", \"Unit\", \"Percentage bias\"]\n",
    "# tidy Variable\n",
    "df_bias = df_bias.assign(Variable = lambda x: x[\"Variable\"].apply(tidy_name))\n",
    "df_bias.style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Table {i_table}**: Bias of model compared with observations. The bias is calculated as the modelled spatial mean minus the observational spatial mean. The percentage bias is calculated as the model bias divided by the observational spatial mean.\")\n",
    "i_table += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "df_cor = []\n",
    "for ff in ensemble:\n",
    "    variable = os.path.basename(ff).split(\"_\")[1].replace(\".nc\", \"\").title()\n",
    "    if variable.lower() == \"sst\":\n",
    "        variable = \"SST\"\n",
    "    ds_ff = nc.open_data(ff)\n",
    "    ds_ff.set_precision(\"F32\")\n",
    "    if True:\n",
    "        mask_shelf(ds_ff)\n",
    "    else:\n",
    "        mask_all(ds_ff)\n",
    "    ds_ff.cor_space(\"model\", \"observation\")\n",
    "    ff_cor = (\n",
    "        ds_ff\n",
    "        .to_dataframe()\n",
    "        .dropna()\n",
    "        .cor\n",
    "        .values\n",
    "        [0]\n",
    "    )\n",
    "    df_cor.append(pd.DataFrame({\"Variable\": [variable], \"Correlation\": [ff_cor]}))\n",
    "df_cor = pd.concat(df_cor).reset_index(drop=True)\n",
    "df_cor.columns = [\"Variable\", \"Spatial correlation between model and observations\"]\n",
    "# tidy Variable\n",
    "df_cor = df_cor.assign(Variable = lambda x: x[\"Variable\"].apply(tidy_name))\n",
    "df_cor.style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Table {i_table}**: Pearson correlation coefficient between model and observations for annual mean of {', '.join(variables)}. This table compares climatological annual averages of the model and observations across the model's spatial domain. Standard devaiation is normalized by the standard deviation of the observations, and a standard deviation below 1 indicates that the model is less variable than the observations.\") \n",
    "i_table += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "global_grid = False\n",
    "for ff in  glob.glob(\"../../results/temporals/*.nc\"):\n",
    "    ds_ff = nc.open_data(ff)\n",
    "    df_ff = ds_ff.to_dataframe().reset_index()\n",
    "    lat_name = [df_ff.columns[i] for i in range(len(df_ff.columns)) if \"lat\" in df_ff.columns[i]][0]\n",
    "    lat_min = df_ff[lat_name].values.min()\n",
    "    lat_max = df_ff[lat_name].values.max()\n",
    "    if lat_min < -89 and lat_max > 89:\n",
    "        global_grid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "df_cor = []\n",
    "for ff in  glob.glob(\"../../results/temporals/*.nc\"):\n",
    "    ds_ff = nc.open_data(ff)\n",
    "    if global_grid:\n",
    "        ds_ff.to_latlon(lon = [-179.5, 179.5], lat = [-89.5, 89.5], res = 1)\n",
    "    if True:\n",
    "        mask_shelf(ds_ff)\n",
    "    else:\n",
    "        mask_all(ds_ff)\n",
    "    df_ff = ds_ff.to_dataframe().reset_index().dropna()\n",
    "    variable = os.path.basename(ff).split(\"_\")[0].replace(\".nc\", \"\").title()\n",
    "    if variable.lower() == \"sst\":\n",
    "        variable = \"SST\"\n",
    "    df_ff = df_ff.assign(variable = variable)\n",
    "    df_cor.append(df_ff)\n",
    "# tidy variable name\n",
    "\n",
    "\n",
    "df_cor = pd.concat(df_cor).reset_index(drop=True)\n",
    "df_cor = df_cor.assign(variable = lambda x: x[\"variable\"].apply(tidy_name))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_cor -i global_grid\n",
    "\n",
    "library(ggplot2, warn.conflicts = FALSE)\n",
    "world_map <- map_data(\"world\")\n",
    "\n",
    "xlim <- c(min(df_cor$lon), max(df_cor$lon))\n",
    "ylim <- c(min(df_cor$lat), max(df_cor$lat))\n",
    "\n",
    "if (global_grid){\n",
    "        lon_breaks <- c(-180, -120, -60, 0, 60, 120, 180)\n",
    "        lon_labels <- c(\"180°W\", \"120°W\", \"60°W\", \"0°\", \"60°E\", \"120°E\", \"180°E\")\n",
    "        lat_breaks <- c(-60, -30, 0, 30, 60)\n",
    "        lat_labels <- c(\"60°S\", \"30°S\", \"0°\", \"30°N\", \"60°N\")\n",
    "} else {\n",
    "        lon_breaks <- c(-20, -10, 0, 10)\n",
    "        lon_labels <- c(\"20°W\", \"10°W\", \"0°\", \"10°E\")\n",
    "        lat_breaks <- c(40, 50, 60)\n",
    "        lat_labels <- c(\"40°N\", \"50°N\", \"60°N\")\n",
    "}\n",
    "\n",
    "min_val <- min(df_cor$cor)\n",
    "max_val <- max(df_cor$cor)\n",
    "\n",
    "\n",
    "gg <- ggplot(df_cor)+\n",
    "        geom_tile(aes(x  = lon,y =   lat, fill = cor))+ \n",
    "        geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", colour = \"grey\")+\n",
    "        coord_cartesian(xlim = xlim, ylim = ylim)+\n",
    "        scale_x_continuous(breaks = lon_breaks, labels = lon_labels)+\n",
    "        scale_y_continuous(breaks = lat_breaks, labels = lat_labels)+\n",
    "        theme_bw(base_size = 12)+\n",
    "        facet_wrap(~variable)+\n",
    "        labs(fill = \"Correlation coefficient\")+\n",
    "        theme_bw(base_family = \"Helvetica\", base_size = 8) +\n",
    "        theme(\n",
    "          legend.position = \"bottom\", legend.direction = \"horizontal\", legend.box = \"horizontal\", legend.key.width = unit(3.0, \"cm\"),\n",
    "          legend.key.height = unit(0.5, \"cm\")\n",
    "        ) +\n",
    "        labs(x = NULL, y = NULL) +\n",
    "        theme(plot.margin = unit(c(2, 0, 2, 0), \"mm\")) +\n",
    "        theme(plot.title = element_text(hjust = 0.5))\n",
    "        # make the legend 3 cm wide\n",
    "        # theme( legend_key_size = unit(3, \"cm\"))\n",
    "\n",
    "\n",
    "if (min_val < 0 & max_val > 0){\n",
    "        gg <- gg + \n",
    "                scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0, \n",
    "                guide = guide_colorbar(title.position = \"bottom\", title.hjust = 0.5, title.theme = element_text(angle = 0, size = 10, family = \"Helvetica\")),\n",
    "                breaks = seq(-1, 1, 0.25))\n",
    "}\n",
    "if (min_val > 0){\n",
    "        gg <- gg + \n",
    "                scale_fill_viridis_c(\n",
    "                guide = guide_colorbar(title.position = \"bottom\", title.hjust = 0.5, title.theme = element_text(angle = 0, size = 10, family = \"Helvetica\"))\n",
    "                )\n",
    "}\n",
    "gg\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Figure {i_figure}**: Spatial correlation (Pearson correlation coefficient) between model and observations for annual mean of {', '.join(variables)}. This figure compares climatological monthly averages of the model and observations across the model's spatial domain.\")\n",
    "i_figure += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall ability of the model reproduce the seasonality of each variable was estimated by calculating the spatial mean of the Pearson correlation coefficient between the model and the observations. The spatial mean was calculated by averaging the correlation coefficient of each grid cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "df_cor = []\n",
    "for ff in  glob.glob(\"../../results/temporals/*.nc\"):\n",
    "    ds_ff = nc.open_data(ff, checks = False)\n",
    "    ds_ff.spatial_mean()\n",
    "    variable = os.path.basename(ff).split(\"_\")[0].replace(\".nc\", \"\").title()\n",
    "    if variable.lower() == \"sst\":\n",
    "        variable = \"SST\"\n",
    "    df_cor.append(pd.DataFrame({\"Variable\": [variable], \"Correlation\": [ds_ff.to_dataframe().reset_index().cor.values[0]]}))\n",
    "\n",
    "df_cor = pd.concat(df_cor).reset_index(drop=True)\n",
    "\n",
    "# tidy Variable\n",
    "df_cor = df_cor.assign(Variable = lambda x: x[\"Variable\"].apply(tidy_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "df_cor.style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Table {i_table}**: Spatial average of the temporal correlation (Pearson correlation coefficient) between model and observations for annual mean of {', '.join(variables)}. The correlation is calculated for each grid cell individually using monthly climatological averages. The spatial average is then calculated for each variable.\")\n",
    "i_table += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
